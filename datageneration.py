# -*- coding: utf-8 -*-
"""DataGeneration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15PVXGCdGMC2XPt5vtnnwD1wiTXnFE-oG
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from datetime import datetime, timedelta,date
import pandas as pd
# %matplotlib inline
from sklearn.metrics import classification_report,confusion_matrix
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from __future__ import division
from sklearn.cluster import KMeans


import chart_studio.plotly as py
import plotly.offline as pyoff
import plotly.graph_objs as go
import plotly.figure_factory as ff

import sklearn
import xgboost as xgb
from sklearn.model_selection import KFold, cross_val_score, train_test_split
import warnings
warnings.filterwarnings("ignore")

#initiate plotly
pyoff.init_notebook_mode()



basic_names = ["user_id","version","minutes_play","day_1_active","day_7_active"]

it = 0
def Generate_Sample_data(number_of_datapoints, version):
    global it
    data = np.array([1000*it + np.arange(num_of_datapoints)+1,
                     [version]*num_of_datapoints,
                     np.random.random(size =(num_of_datapoints),) * 100 ,
                     np.random.randint(2,size = num_of_datapoints),
                     np.random.randint(2,size = num_of_datapoints)]).T
    it+=1
    return data
def create_dataframe(num_of_datapoints,version,feature_names):
    return pd.DataFrame(
    data = Generate_Sample_data(num_of_datapoints,version = version),
    # dtype = {"user_id" : 'float64',
    #                                 "version" : 'object',
    #                                 "minutes_play" : 'float64',
    #                                 "day_1_active" : 'float64',
    #                                 "day_7_active" : 'float64'} , 
    columns= feature_names)
    
    
def generate_dataset(num_of_groups,num_of_datapoints,feature_names):
    control_group = create_dataframe(num_of_datapoints,"control",feature_names)
    Treatment_groups = [create_dataframe(num_of_datapoints,
                                     "treatment_"+str(i+1),feature_names) for i in range(num_of_groups)]
    return pd.concat([control_group,pd.concat(Treatment_groups)])
def generte_treatment_results(num_of_groups,num_of_datapoints,feature_names):
    return np.array([np.random.randint(2,size = num_of_datapoints) for i in range(num_of_groups)])

num_of_groups = int(input("Input number of groups"))
feature_names = basic_names
num_of_datapoints =  int(input("Input number of datapoint per group"))
data = generate_dataset(num_of_groups,num_of_datapoints,feature_names) 
results = generte_treatment_results(num_of_groups,num_of_datapoints,feature_names)

data.head(),data.tail()

for each in data.columns:
    if each == 'user_id':
        data[each] = np.int64(data[each])
    elif each!='version':
        data[each]=np.float64(data[each])

results[:5]

import pandas as pd
import scipy.stats as stats

import numpy as np
import pandas as pd
import scipy.stats as stats
import statsmodels.stats.api as sms
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
from math import ceil
from scipy.stats import f_oneway
from statsmodels.stats.power import TTestIndPower

effect = 0.1
alpha = 0.06
power = 0.9
analysis = TTestIndPower()
result = analysis.solve_power(effect, power = power,nobs1= None, ratio = 1.0, alpha = alpha)
print('Sample Size: %.3f' % round(result))

TTestIndPower().plot_power(dep_var='nobs',
nobs=np.array(range(5, 1000)),
effect_size=np.array([0.1, 0.06, 0.9]),
title='Power of t-Test')

data.dtypes

def plot_dist_players(data):
  print("yes")
  print(data['minutes_play'].round())
  print(round(data['minutes_play']))
  data['minutes_play_integers'] = round(data['minutes_play'])
  print("yes")
  plot_df = data.groupby('minutes_play_integers')['user_id'].count()
  ax = plot_df.head(n=50).plot(x="minutes_play_integer", y="user_id", kind="hist")
  ax.set_xlabel("Duration of Video Played in Minutes")
  ax.set_ylabel("User Count")
  return ax

plot_dist_players(data)



def boot_means(data):
    boot_means = []
    for i in range(10000):
        boot_sample = data.sample(frac=1, replace=True).groupby('version')['day_1_active'].mean()
        boot_means.append(boot_sample)
    boot_means = pd.DataFrame(boot_means)
    return boot_means

boot_means(data)



def boot_means_diff(data):
  boot_means = []
  for i in range(10000):
    boot_sample = data.sample(frac=1, replace=True).groupby('version')['day_1_active'].mean()
    boot_means.append(boot_sample)
    boot_means = pd.DataFrame(boot_means)
  boot_means['diff'] = (boot_means['treatment_1'] - boot_means['control']) / boot_means['control'] * 100
  return boot_means['diff']

boot_means_diff(data)

def diff_means(data):
  boot_means = []
  for i in range(10000):
    boot_sample = data.sample(frac = 1, replace = True).groupby('version')['day_1_active']
    boot_means.append(boot_sample)
    boot_means = pd.DataFrame(boot_means)
    boot_means['diff'] = (boot_means['treatment_1'] - boot_means['control']) / boot_means['control'] * 100
  ax = boot_means['diff'].plot(kind = 'kde')
  ax.set_xlabel("% diff in means")
  return ax

diff_means(data)

def boot_7d(data):
  boot_7d = []

  for i in range(10000):
      boot_mean = data.sample(frac=1,replace=True).groupby('version')['day_7_active'].mean() 
      boot_7d.append(boot_mean)
      
  boot_7d = pd.DataFrame(boot_7d)

  boot_7d['diff'] = (boot_7d['treatment_1'] - boot_7d['control'])/boot_7d['control'] *100
  ax = boot_7d['diff'].plot(kind = 'kde')
  ax.set_xlabel("% diff in means")
  return ax

boot_7d(data)

def conversion_rate(data):
  plt.figure(figsize=(8,6))

  sns.barplot(x=data['version'], y=data['day_7_active'], ci=False)

  plt.ylim(0, 1)
  plt.title('Conversion rate by group', pad=30)
  plt.xlabel('Group', labelpad=15)
  plt.ylabel('Converted (proportion)', labelpad=20);
  return plt

conversion_rate(data)

from statsmodels.stats.proportion import proportions_ztest, proportion_confint

def results(data):
  control_results = data[data['version'] == 'control']
  treatment1_results = data[data['version'] == 'treatment_1']
  treatment2_results = data[data['version'] == 'treatment_2']
results(data)

n_con = control_results.count()
n_treat1 = treatment1_results.count()
successes = [control_results.sum(), treatment1_results.sum()]
nobs = [n_con, n_treat1]

z_stat, pval = proportions_ztest(successes, nobs=nobs)
(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)

print(f'z statistic: {z_stat:.2f}')
print(f'p-value: {pval:.3f}')
print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')
print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')

ctrl = data[data['version'] == 'control']['minutes_play']
treatment = data[data['version'] == 'treatment_1']['minutes_play']

from scipy.stats import ttest_ind
def t_test(data):
  test_res = ttest_ind(treatment, ctrl)
  return test_res
t_test(data)

def p_value(data):
  test_res = ttest_ind(treatment, ctrl)
  return test_res.pvalue
p_value(data)

a_stats = data[data.version=='control'].minutes_play
b_stats = data[data.version=='treatment_1'].minutes_play
c_stats = data[data.version=='treatment_'].minutes_play





def one_anova_test(a_stats,b_stats,c_stats):
    test_result = stats.f_oneway(a_stats, b_stats, c_stats)
    if test_result[1] < 0.05:
        print('result is significant')
    else:
        print('result is not significant')

one_anova_test(a_stats,b_stats,c_stats)

import statsmodels.formula.api as smf 
from statsmodels.stats.anova import anova_lm
data['group'] = 'control'
model = smf.ols(formula='minutes_play ~ version + group', data=data).fit()
aov_table = anova_lm(model, typ=2)







